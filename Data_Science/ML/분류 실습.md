## 분류 실습

- 모델의 평가 방법

  - TP : 암인데 암이라고 함

  - TN : 암이 아닌데, 암이 아니라고 함

  - FP : 암이 아닌데, 암이라고 함

  - FN : 암인데, 암이 아니라고 함

  - 보통 FP와 FN이 문제가 된다.

    - 둘의 중요도 차이는 크다.

  - 정확도 (Accuracy)

    - 만든 모델이 예측을 올바르게 한 비율
    - (TP + TN) / (TP + TN + FP + FN)

  - 정밀도 (Precision)

    - TP / (TP + FP)
    - 암이 맞다고 진단 내린 판단 중에서
      - 실제로 암이 맞는 경우
    - 이것을 정밀도라고 함

  - 재현률 (Recall)

    - TP / (TP + FN)
      - 실제로 암이 맞는 애들중에
        - 암이라고 맞춘 확률

  - 암의 예시에서는 

    - 실제로 암인데 암이 아니라고하면 큰일남;;
    - 따라서 재현률이 극히 높아야함 (FN이 극히 낮아야함)

  - 정밀도와 재현률 예시

    - 스팸메일이 있을 때,
    - TP = 8 (스팸 인걸 스팸 이라고)
    - TN = 17 (스팸 아닌걸 스팸 아니라고)
    - FP = 2 (스팸 아닌걸 스팸이라고)
    - FN = 3 (스팸 인걸 스팸 아니라고)
    - 이라고 하자
    - 더 신경써야하는 건 뭘까?
      - 스팸 아닌걸 스팸이라고 하면 큰일난다;;
      - 따라서 정밀도가 극히 높아야한다.
    - raising the classification threshold reduces false positives, thus raising precision.

    - 스팸 예시에서
    - threshold를 raise 한다는 말은
      - 각 data마다 spam일 확률이 0.7 넘을 경우에만 스팸으로 분류
      - 그럼? 스팸으로 식별하는 data가 적어진다..
      - 스팸 아니라고 식별하는 data가 많아진다.
      - 그럼 보통 FP는 감소하고, FN은 증가한다.

- ROC-AUC

  - **receiver operating characteristic curve**
  - 모든 분류 임계값에서 분류 모델의 성능을 보여주는 그래프입니다.
  - 이 곡선은 두 개의 매개변수를 표시합니다.
    - TPR : 재현률 ( TP / (TP + FN) ) 
      - 실제 스팸인 메일이 스팸판정 받는 확률
      - Sensitivity
      - 민감도
    - FPR : ( FP / (FP + TN) ) 
      - 스팸 아닌 메일이 스팸판정 받을 확률
      - Specificity
      - 특이도
  - ROC 곡선은 다양한 분류 임계값에서 TPR 대 FPR을 표시합니다. 
  - 분류 임계값을 낮추면 더 많은 항목이 양성으로 분류되어 거짓 양성과 참 양성이 모두 증가합니다.

---

# Santander Customer Satisfaction

### 데이터 설명

- You are provided with an anonymized dataset containing a large number of numeric variables. The "TARGET" column is the variable to predict. It equals one for unsatisfied customers and 0 for satisfied customers.

- 라벨이 1이면 불만을 가진 고객, 0이면 만족한 고객
  - 이진분류
- 목표 
  - 테스트 세트의 각 고객이 만족하지 못한 고객일 확률을 예측하는 것

### 데이터 전처리

- ```python
  import numpy as np 
  import pandas as pd 
  import matplotlib.pyplot as plt
  import matplotlib
  import warnings
  warnings.filterwarnings('ignore')
  
  cust_df = pd.read_csv("./train_santander.csv", encoding='latin-1')
  print('dataset shape:', cust_df.shape)
  cust_df.head(3)
  cust_df.info()
  '''
  <class 'pandas.core.frame.DataFrame'>
  RangeIndex: 76020 entries, 0 to 76019
  Columns: 371 entries, ID to TARGET
  dtypes: float64(111), int64(260)
  memory usage: 215.2 MB
  '''
  # 총 데이터 76020개 있음...
  ```

- 먼저 데이터를 DataFrame으로 읽는다.

- info()도 확인해본다.

- 우리의 label은 TARGET 이므로 TARGET에 대해서도 알아보자

- ```python
  print(cust_df['TARGET'].value_counts())
  # 76020명 중 만족 몇명, 불만족 몇명인지.. 세어보고
  unsatisfied_cnt = cust_df[cust_df['TARGET'] == 1].TARGET.count()
  total_cnt = cust_df.TARGET.count()
  print('unsatisfied 비율은 {0:.2f}'.format((unsatisfied_cnt / total_cnt)))
  
  # 전체 4프로 정도가 불만족 했음 (0.04)
  ```

- cust_df.describe( )

  - 컬럼별로 갯수, 평균, 표준편차, 최소, 최대, 중앙값 등등 확인해보자

  - 이상하거나 필요없는 feature를 정정하거나 삭제해야한다.

  - ```python
    # var3 피처 값 대체 및 ID 피처 드롭
    cust_df['var3'].replace(-999999, 2, inplace=True)
    cust_df.drop('ID', axis=1, inplace=True)
    
    # 피처 세트와 레이블 세트분리. 레이블 컬럼은 DataFrame의 맨 마지막에 위치해 컬럼 위치 -1로 분리
    X_features = cust_df.iloc[:, :-1]
    y_labels = cust_df.iloc[:, -1]
    ```

- 학습, 테스트 데이터를 나눈다.

  - ```python
    from sklearn.model_selection import train_test_split
    
    X_train, X_test, y_train, y_test = train_test_split(X_features, y_labels,
                                                        test_size=0.2, random_state=0)
    train_cnt = y_train.count()
    test_cnt = y_test.count()
    print('학습 세트 Shape:{0}, 테스트 세트 Shape:{1}'.format(X_train.shape , X_test.shape))
    
    print(' 학습 세트 레이블 값 분포 비율')
    print(y_train.value_counts()/train_cnt)
    print('\n 테스트 세트 레이블 값 분포 비율')
    print(y_test.value_counts()/test_cnt)
    
    '''
     학습 세트 레이블 값 분포 비율
    0    0.960964
    1    0.039036
    Name: TARGET, dtype: float64
    
     테스트 세트 레이블 값 분포 비율
    0    0.9583
    1    0.0417
    Name: TARGET, dtype: float64
    '''
    # 각각 4프로씩 잘 분포 되어있음 굿
    ```

- ```python
  from xgboost import XGBClassifier
  from sklearn.metrics import roc_auc_score
  
  # n_estimators는 500으로, learning_rate 0.05, random state는 예제 수행 시마다 동일 예측 결과를 위해 설정. 
  xgb_clf = XGBClassifier(n_estimators=500, 
                          learning_rate=0.05, 
                          random_state=156)
  
  # 성능 평가 지표를 auc로, 조기 중단 파라미터는 100으로 설정하고 학습 수행. 
  xgb_clf.fit(X_tr, y_tr, 
              early_stopping_rounds=100, 
              eval_metric='auc', # 모델의 평가는 auc로 진행
              eval_set=[(X_tr, y_tr), (X_val, y_val)])
  
  xgb_roc_score = roc_auc_score(y_test, xgb_clf.predict_proba(X_test)[:, 1])
  print('ROC AUC: {0:.4f}'.format(xgb_roc_score))
  
  from sklearn.metrics import accuracy_score
  # 정확도도 함 보자
  print(accuracy_score(y_test, xgb_clf.predict(X_test)))
  ```

- 하이퍼 파라미터 튜닝을 해보자

  - ```python
    from hyperopt import hp
    
    # max_depth는 5에서 15까지 1간격으로, 
    # min_child_weight는 1에서 6까지 1간격으로
    # colsample_bytree는 0.5에서 0.95사이, 
    # learning_rate는 0.01에서 0.2사이 정규 분포된 값으로 검색. 
    # 많이 건드는 파라미터들만 해보자고..
    
    xgb_search_space = {
        'max_depth': hp.quniform('max_depth', 5, 15, 1), 
        'min_child_weight': hp.quniform('min_child_weight', 1, 6, 1),
        'colsample_bytree': hp.uniform('colsample_bytree', 0.5, 0.95),
        'learning_rate': hp.uniform('learning_rate', 0.01, 0.2)
    	}
    
    from sklearn.model_selection import KFold
    from sklearn.metrics import roc_auc_score
    
    # 목적 함수 설정. 
    # 추후 fmin()에서 입력된 search_space값으로 XGBClassifier 교차 검증 학습 후 -1* roc_auc 평균 값을 반환.
    def objective_func(search_space):
        xgb_clf = XGBClassifier(n_estimators=100, 
                                max_depth=int(search_space['max_depth']),
                                min_child_weight=int(search_space['min_child_weight']),
                                colsample_bytree=search_space['colsample_bytree'],
                                learning_rate=search_space['learning_rate']
                               )
        # 3개 k-fold 방식으로 평가된 roc_auc 지표를 담는 list
        roc_auc_list= []
        
        # 3개 k-fold방식 적용 
        kf = KFold(n_splits=3)
        # X_train을 다시 학습과 검증용 데이터로 분리
        for tr_index, val_index in kf.split(X_train):
            # kf.split(X_train)으로 추출된 학습과 검증 index값으로 학습과 검증 데이터 세트 분리 
            X_tr, y_tr = X_train.iloc[tr_index], y_train.iloc[tr_index]
            X_val, y_val = X_train.iloc[val_index], y_train.iloc[val_index]
            # early stopping은 30회로 설정하고 추출된 학습과 검증 데이터로 XGBClassifier 학습 수행. 
            xgb_clf.fit(X_tr, y_tr, early_stopping_rounds=30, eval_metric='auc',
                       eval_set=[(X_tr, y_tr), (X_val, y_val)])
        
            # 1로 예측한 확률값 추출후 roc auc 계산하고 평균 roc auc 계산을 위해 list에 결과값 담음. 
            score = roc_auc_score(y_val, xgb_clf.predict_proba(X_val)[:, 1])
            roc_auc_list.append(score)
            
        # 3개 k-fold로 계산된 roc_auc값의 평균값을 반환하되, 
        # HyperOpt는 목적함수의 최소값을 위한 입력값을 찾으므로 -1을 곱한 뒤 반환. 
        return -1 * np.mean(roc_auc_list)
    
    # 파라미터 찾아보자
    from hyperopt import fmin, tpe, Trials
    
    trials = Trials()
    
    # fmin()함수를 호출. max_evals지정된 횟수만큼 반복 후 목적함수의 최소값을 가지는 최적 입력값 추출.
    best = fmin(fn=objective_func,
                space=xgb_search_space,
                algo=tpe.suggest,
                max_evals=50, # 최대 반복 횟수를 지정합니다.
                trials=trials, rstate=np.random.default_rng(seed=30))
    
    print('best:', best)
    ```

- 튜닝 끝나고 찾은 파라미터를 집어넣어서 다시 학습시켜보자

  - ```python
    # n_estimators를 500증가 후 최적으로 찾은 하이퍼 파라미터를 기반으로 학습과 예측 수행.
    xgb_clf = XGBClassifier(n_estimators=500, learning_rate=round(best['learning_rate'], 5),
                            max_depth=int(best['max_depth']), min_child_weight=int(best['min_child_weight']), 
                            colsample_bytree=round(best['colsample_bytree'], 5)   
                           )
    
    # evaluation metric을 auc로, early stopping은 100 으로 설정하고 학습 수행. 
    xgb_clf.fit(X_tr, y_tr, early_stopping_rounds=100, 
                eval_metric="auc",eval_set=[(X_tr, y_tr), (X_val, y_val)])
    
    xgb_roc_score = roc_auc_score(y_test, xgb_clf.predict_proba(X_test)[:,1])
    print('ROC AUC: {0:.4f}'.format(xgb_roc_score))
    ```

- 어떤 feature가 중요한지 한번 보자

  - ```python
    from xgboost import plot_importance
    import matplotlib.pyplot as plt
    %matplotlib inline
    
    fig, ax = plt.subplots(1,1,figsize=(10,8))
    plot_importance(xgb_clf, ax=ax , max_num_features=20,height=0.4)
    ```

---

### LightGBM

```python
from lightgbm import LGBMClassifier

lgbm_clf = LGBMClassifier(n_estimators=500)

eval_set=[(X_tr, y_tr), (X_val, y_val)]
lgbm_clf.fit(X_tr, y_tr, early_stopping_rounds=100, eval_metric="auc", eval_set=eval_set)

lgbm_roc_score = roc_auc_score(y_test, lgbm_clf.predict_proba(X_test)[:,1])
print('ROC AUC: {0:.4f}'.format(lgbm_roc_score))

lgbm_search_space = {'num_leaves': hp.quniform('num_leaves', 32, 64, 1),
                     'max_depth': hp.quniform('max_depth', 100, 160, 1),
                     'min_child_samples': hp.quniform('min_child_samples', 60, 100, 1),
                     'subsample': hp.uniform('subsample', 0.7, 1),
                     'learning_rate': hp.uniform('learning_rate', 0.01, 0.2)
                    }

def objective_func(search_space):
    lgbm_clf =  LGBMClassifier(n_estimators=100, num_leaves=int(search_space['num_leaves']),
                               max_depth=int(search_space['max_depth']),
                               min_child_samples=int(search_space['min_child_samples']), 
                               subsample=search_space['subsample'],
                               learning_rate=search_space['learning_rate'])
    # 3개 k-fold 방식으로 평가된 roc_auc 지표를 담는 list
    roc_auc_list = []
    
    # 3개 k-fold방식 적용 
    kf = KFold(n_splits=3)
    # X_train을 다시 학습과 검증용 데이터로 분리
    for tr_index, val_index in kf.split(X_train):
        # kf.split(X_train)으로 추출된 학습과 검증 index값으로 학습과 검증 데이터 세트 분리 
        X_tr, y_tr = X_train.iloc[tr_index], y_train.iloc[tr_index]
        X_val, y_val = X_train.iloc[val_index], y_train.iloc[val_index]

        # early stopping은 30회로 설정하고 추출된 학습과 검증 데이터로 XGBClassifier 학습 수행. 
        lgbm_clf.fit(X_tr, y_tr, early_stopping_rounds=30, eval_metric="auc",
           eval_set=[(X_tr, y_tr), (X_val, y_val)])

        # 1로 예측한 확률값 추출후 roc auc 계산하고 평균 roc auc 계산을 위해 list에 결과값 담음.
        score = roc_auc_score(y_val, lgbm_clf.predict_proba(X_val)[:, 1]) 
        roc_auc_list.append(score)
    
    # 3개 k-fold로 계산된 roc_auc값의 평균값을 반환하되, 
    # HyperOpt는 목적함수의 최소값을 위한 입력값을 찾으므로 -1을 곱한 뒤 반환.
    return -1*np.mean(roc_auc_list)

from hyperopt import fmin, tpe, Trials

trials = Trials()

# fmin()함수를 호출. max_evals지정된 횟수만큼 반복 후 목적함수의 최소값을 가지는 최적 입력값 추출. 
best = fmin(fn=objective_func, space=lgbm_search_space, algo=tpe.suggest,
            max_evals=50, # 최대 반복 횟수를 지정합니다.
            trials=trials, rstate=np.random.default_rng(seed=30))

print('best:', best)

lgbm_clf =  LGBMClassifier(n_estimators=500, num_leaves=int(best['num_leaves']),
                           max_depth=int(best['max_depth']),
                           min_child_samples=int(best['min_child_samples']), 
                           subsample=round(best['subsample'], 5),
                           learning_rate=round(best['learning_rate'], 5)
                          )

# evaluation metric을 auc로, early stopping은 100 으로 설정하고 학습 수행. 
lgbm_clf.fit(X_tr, y_tr, early_stopping_rounds=100, 
            eval_metric="auc",eval_set=[(X_tr, y_tr), (X_val, y_val)])

lgbm_roc_score = roc_auc_score(y_test, lgbm_clf.predict_proba(X_test)[:,1])
print('ROC AUC: {0:.4f}'.format(lgbm_roc_score))
```

- csv 내보내는법

  ```
  df.to_csv('./df.csv', index=False)
  ```

---

# Credit Card Fraud Detection

