완벽해. AVRO와 Parquet 파일 포맷에 대해 Zero Base부터 깊이 있게, 가능한 한 길고 상세하게 정리해서 설명할게. 역사, 내부 구조, 압축 방식, 사용처, 선택 기준, 실제 예제까지 모두 포함해서 리포트 형식으로 제공할게.

자료가 정리되면 바로 알려줄게.

# Avro와 Parquet 파일 포맷 심층 분석

## 1. 개발 배경과 역사, 설계 목적

### Avro의 배경과 설계 목적
Avro는 2009년 Apache Hadoop 프로젝트의 일환으로 **더그 커팅(Doug Cutting)**에 의해 개발된 데이터 직렬화 시스템입니다. 주요 목표는 **풍부한 데이터 구조**를 지원하면서도 **컴팩트하고 빠른 이진 포맷**으로 데이터를 저장·전달하는 것이었습니다. Avro는 Hadoop 에코시스템에서 **다양한 언어 간 효율적인 데이터 교환**을 위해 설계되었고, 초기에 Hadoop의 기존 **SequenceFile 포맷의 한계**를 극복하기 위한 대안으로 등장했습니다. Avro는 개발 후 Hadoop 에코시스템의 핵심 구성요소로 자리잡았으며, 수많은 빅데이터 및 실시간 분석 도구에서 채택되었습니다.

이 포맷의 **설계 철학** 중 하나는 **스키마(schema) 기반**의 데이터 처리를 지원하는 것입니다. Avro 데이터 파일에는 **데이터와 함께 해당 스키마를 자체적으로 내장**하고 있어서, 데이터를 읽는 쪽에서 사전에 스키마를 몰라도 파일 자체만으로 해석이 가능합니다. 이러한 **자체 기술(self-describing)** 특성 덕분에 Avro는 **스키마 진화(schema evolution)** 를 강력히 지원합니다. 즉, 시간이 지남에 따라 스키마에 필드가 추가되거나 타입이 변경되어도, 새 스키마와 구 스키마 간의 호환성을 유지하며 데이터 읽기가 가능합니다. 이로써 Avro는 데이터 파이프라인에서 **전후방 호환성(Backward/Forward compatibility)**을 보장하여, 실무에서 스키마 변경이 잦은 환경에서도 안정적으로 사용할 수 있습니다.

정리하면 Avro는 **행 지향(row-based)의 이진 포맷**으로, 빠른 직렬화/역직렬화와 다국어 지원, 그리고 진화 가능한 스키마를 목표로 설계되었습니다. 특히 **실시간 로그나 트랜잭션 데이터**와 같이 **전체 레코드의 빠른 쓰기/읽기**가 중요한 상황에서 유리하며, 다양한 프로그래밍 언어(API 제공)와 통신(RPC)에서도 쓰입니다.

### Parquet의 배경과 설계 목적
Parquet는 2013년 Twitter와 Cloudera의 개발자들이 공동으로 만들어 Apache에 기부한 **컬럼 지향 열 저장(columnar storage)** 파일 포맷입니다. Google의 내부 논문 **Dremel**(빅쿼리의 기반 아이디어)에서 영감을 받아, Hadoop 생태계에 고성능 컬럼식 저장을 도입하기 위해 설계되었으며 개발 당시 **"Red Elm"**(Dremel의 애너그램)이라는 코드명으로 불렸습니다. Parquet의 목표는 **Hadoop 환경에서의 최신 컬럼 저장 기술**을 제공하는 것이었고, Hive의 RCFile이나 ORC 등 기존 포맷의 한계를 개선하여 **플랫폼에 구애받지 않는 효율적인 컬럼 지향 포맷**을 만드는 것이었습니다.

2013년 오픈 소스로 공개된 이후, Parquet는 빠르게 Apache Top-Level 프로젝트로 승격되었고 Hadoop 기반의 컬럼식 저장 표준으로 자리잡았습니다. 이 포맷은 **대용량 데이터 분석에 최적화**되어 있어서, **열 단위의 고속 쿼리 처리**와 **효율적인 압축**을 강점으로 내세웁니다. Parquet는 **복잡한 중첩 구조(nested structure)**의 데이터도 표현 가능하며, 하나의 파일에 다수의 열과 행 그룹을 담아 **대규모 데이터 세트를 효율적으로 스캔**할 수 있습니다. 또한 다양한 빅데이터 처리 도구(예: Hadoop, Spark, Presto, Hive 등) 및 언어(Java, Python, C++ 등)에서 폭넓게 지원되어 **호환성이 뛰어납니다**.

요약하면 Parquet는 **열 지향(column-based)** 저장으로, **데이터 분석(OLAP)** 워크로드에서 높은 성능을 내는 것이 설계 목표입니다. **한 번 쓰고 여러 번 읽는(Write once, read many)** 데이터 웨어하우스 시나리오에 적합하며, 열별로 특화된 인코딩/압축을 통해 저장 공간을 절약하고 쿼리 속도를 향상시키는 것을 중점으로 만들어졌습니다.

## 2. 파일 내부 구조 (헤더, 메타데이터, 데이터 섹션)

### Avro 파일 내부 구조
Avro 데이터 파일(일명 **Object Container File**)은 **헤더(header)**와 하나 이상의 **데이터 블록(data block)**으로 구성됩니다. 즉, 파일 시작 부분에 메타데이터가 담긴 헤더가 나오고, 그 뒤에 실제 레코드들을 담은 블록들이 이어지는 구조입니다.

- **헤더(Header)**: Avro 헤더에는 다음 정보가 들어 있습니다:
  - **매직 넘버**: 파일의 시작 4바이트는 ASCII 문자 `'O' 'b' 'j' 0x01`로, Avro 파일임을 나타내는 고유 시그니처입니다.
  - **파일 메타데이터**: 헤더에는 키-값 쌍의 메타데이터 맵이 포함되며, 이 안에 반드시 `"avro.schema"` 키로 **데이터 스키마(JSON 문자열)**가 저장됩니다. (옵션으로 `"avro.codec"` 키에 압축 코덱 정보가 있을 수 있습니다. 지정되지 않으면 기본값은 `null` 즉 무압축입니다.)
  - **동기화 마커(Sync Marker)**: 임의로 생성된 **16바이트의 동기화 표시자**가 헤더의 끝에 포함됩니다. 이 sync 마커는 이후 데이터 블록 경계 표시 및 파일 분할에 활용됩니다.

- **데이터 블록(Data Block)**: 헤더 다음부터는 N개의 레코드를 담은 데이터 블록들이 순차적으로 기록됩니다. 각 블록은 아래와 같은 구조를 가집니다:
  - **레코드 개수**: 해당 블록에 들어있는 레코드(record)의 수를 나타내는 **long 타입**의 숫자.
  - **블록 크기**: 블록 내 직렬화된 레코드들의 바이트 크기(long 타입). (압축이 적용된 경우 **압축된 크기** 기준으로 기록됩니다.)
  - **레코드 데이터**: 실제 레코드들의 바이너리 직렬화 데이터가 연속으로 들어갑니다. (압축 코덱이 지정되었다면 이 부분은 압축되어 저장됩니다.)
  - **동기화 마커**: 각 블록의 끝에도 해당 파일의 16바이트 sync 마커가 삽입됩니다. 이를 통해 **블록 경계를 식별**할 수 있습니다.

Avro의 데이터 레코드는 지정된 **스키마에 따라 바이너리 인코딩**되는데, 필드 이름이나 타입 같은 메타정보는 데이터 부분에 포함되지 않고 오직 헤더의 스키마에만 기록되기 때문에 **데이터 저장이 매우 효율적**입니다. 예를 들어, Avro는 문자열 등의 필드를 저장할 때 필드명 없이 값만 저장하고, 정수형은 가변 길이 바이너리(zigzag 인코딩)로 저장하여 불필요한 바이트를 줄입니다. 또한 Avro는 **JSON 포맷으로도** 직렬화할 수 있지만, 일반적으로는 훨씬 크기가 작고 빠른 **이진 인코딩**을 사용합니다.

Avro 파일은 **헤더에 스키마가 내장**되어 있으므로, 파일만 있으면 어떤 프로그램이든 해당 스키마를 읽어 데이터 필드를 해석할 수 있습니다. 위에서 언급한 sync 마커 덕분에 Avro 파일은 **HDFS 상에서 스플릿(split) 가능**합니다. 즉, 대용량 Avro 파일을 여러 분할로 나눠 병렬 처리할 때, 리더가 임의의 오프셋에서 파일을 읽다가 sync 마커를 찾아 블록의 시작을 동기화한 후부터 올바른 레코드들을 읽을 수 있습니다. (Parquet 등은 파일 끝의 메타데이터로 분할 정보를 갖지만, Avro는 헤더-블록 구조상 sync 마커로 분할 처리합니다.)

**예시:** Avro 파일 헤더에 포함되는 스키마는 JSON으로 기술됩니다. 아래는 간단한 Avro 스키마의 예입니다:

```json
{  
  "namespace": "com.howdy",
  "name": "some_schema",
  "type": "record",
  "fields": [
    { "name": "field1", "type": "string" },
    { "name": "field2", "type": "int" },
    { "name": "field3", "type": "long" },
    { "name": "field4", "type": "boolean" }
  ]
}
```

위 스키마를 헤더에 담은 Avro 파일은, 데이터 블록에 각 필드값을 순서대로 이진 인코딩하여 저장합니다. Avro 파일을 hexdump로 보면 첫 바이트에 `4F 62 6A 01` (`Obj\x01`) 매직 넘버와 `"avro.codec": "null"`, `"avro.schema": "{...}"` 등의 메타데이터 문자열이 나타나고 이후 이진 데이터가 이어지는 것을 확인할 수 있습니다.

### Parquet 파일 내부 구조
Parquet 파일은 **헤더(header)**, 하나 이상의 **데이터 row group(행 그룹)**으로 이루어진 **본체(data block)**, 그리고 **푸터(footer)**로 구성됩니다. 전체 구조는 아래 그림과 같이 헤더와 푸터에 Magic Number "PAR1"이 있고, 데이터는 **Row Group** 단위로 나뉘어 저장됩니다:

 *Parquet 파일 포맷 구조. 헤더에 "PAR1" 매직넘버가 있고, 데이터 섹션은 여러 Row Group(각 Row Group은 다수의 Column Chunk로 구성)으로 이루어진다. 파일 끝의 푸터에 전체 메타데이터와 다시 "PAR1" 매직넘버가 기록된다.*

- **헤더(Header)**: 파일의 맨 앞 4바이트에 **매직 넘버 "PAR1"**이 적혀 있습니다. 이 시그니처는 해당 파일이 Parquet 포맷임을 나타냅니다. (헤더 자체에 이 외의 별도 메타데이터는 없고, 주요 메타데이터는 모두 푸터에 기록됩니다.)

- **데이터 섹션(Data Blocks)**: 실제 데이터는 하나 이상의 **Row Group**으로 나누어 저장됩니다. **Row Group(행 그룹)**이란, **연속된 행들**(예: 1~10만 번째 레코드)을 묶은 데이터 덩어리입니다. 각 Row Group 안에는 **각 컬럼별로 Column Chunk**(열 덩어리)가 저장됩니다. 즉, Parquet는 **먼저 일정한 행 범위를 Row Group으로 묶고**, 그 내부에서 **컬럼별로 데이터를 분리**하여 저장합니다. 예를 들어 스키마에 5개의 필드(컬럼)가 있다면, Row Group 내에 5개의 Column Chunk가 있고, 첫 번째 Column Chunk에는 그 Row Group 구간의 모든 행에 대한 첫 번째 컬럼 값들이 모여 있습니다.

  - **Column Chunk(컬럼 덩어리)**: 각 컬럼 청크는 다시 **Pages(페이지)**라는 작은 단위로 쪼개어집니다. 페이지는 일반적으로 수만 행 정도씩 묶은 컬럼 데이터 블록으로, Parquet는 기본적으로 페이지 단위로 압축과 인코딩을 적용합니다. 모든 페이지들은 동일 컬럼의 데이터를 담고 있기 때문에 **데이터 타입과 분포가 유사**하며, 그 결과 **고율의 압축 효율**을 얻을 수 있습니다. 

  - 각 Column Chunk는 페이지들의 연속으로 이루어져 있고, 필요에 따라 해당 컬럼에 대한 **메타데이터(예: 최소/최대값, null 개수 등)**를 담습니다. Row Group 내의 Column Chunk들은 순차적으로 파일에 기록되며, 한 Row Group의 모든 컬럼 청크를 쓰고 나면 다음 Row Group의 컬럼 청크들이 이어지는 식입니다. (Row Group 경계는 푸터 메타데이터에 오프셋 정보로 기록됩니다.)

- **푸터(Footer)**: 파일의 마지막 부분에는 **메타데이터 풋터**가 위치합니다. 푸터에는 해당 Parquet 파일에 대한 전반적인 메타데이터가 JSON 또는 바이너리 형태로 포함되며, 주요 내용은 다음과 같습니다:
  - **파일 버전** (Parquet format version)
  - **스키마**: 파일에 저장된 데이터의 스키마 정의 (필드명과 타입 구조)
  - **키-값 메타데이터**: 추가적인 사용자 정의 메타데이터가 있을 경우 포함
  - **Row Group 메타데이터**: 각 Row Group의 오프셋(파일 내 위치)과 크기, 그리고 Row Group 내 각 컬럼 청크의 메타데이터가 기록됩니다. 컬럼 메타데이터에는 해당 컬럼의 데이터 타입, 경로(중첩 구조일 경우), **인코딩 방식**, **값의 개수**, **압축 여부 및 압축된 크기**와 **uncompressed 크기**, 그리고 **컬럼 통계치(최소값, 최대값, Null 개수 등)**가 포함됩니다. 이러한 메타 정보로 쿼리 엔진은 특정 컬럼의 일부만 읽거나, 특정 값 범위의 데이터 블록을 빠르게 스킵할 수 있습니다.
  - **푸터 길이**: 푸터 메타데이터의 바이트 길이를 나타내는 4바이트 정수가 기록됩니다.
  - **매직 넘버**: 마지막으로 다시 한번 4바이트 `"PAR1"`이 찍혀서 파일이 끝납니다.

푸터에 메타데이터를 몰아넣는 Parquet의 설계는 **한 번의 파일 쓰기 패스**로 전체 메타정보를 나중에 기록할 수 있게 해줍니다. 즉, 데이터를 모두 기록한 후에 그 요약 정보를 맨 끝에 적는 방식입니다. 이로 인해 파일을 읽을 때는 먼저 **끝부분으로 가서 푸터 길이와 메타데이터를 읽은 후**, 거기에 기록된 오프셋 정보를 활용해 각 Row Group과 컬럼을 접근합니다. 이러한 구조 덕분에 **Parquet 파일도 분할(스플릿) 처리에 적합**합니다. 분산 환경에서 Parquet를 읽을 때, **푸터만 읽어서 블록 경계(RG 범위)를 파악한 뒤** 작업자 간에 Row Group 단위로 파일을 나눠 병렬 처리할 수 있습니다. (반대로 Avro는 헤더에 메타데이터가 있으므로 블록 경계를 sync marker로 찾는 방식을 쓰지만, Parquet는 푸터에 명시된 바이트 오프셋으로 바로 점프합니다.)

정리하면, Parquet 파일은 **헤더("PAR1") - 데이터(Row Groups) - 푸터(메타데이터 + "PAR1")** 순서로 구성되며, 데이터는 **행을 묶고 열로 나눈 2차원적 구조**로 저장됩니다. 이러한 내부 구조는 Parquet가 **열별 I/O 최적화**와 **효율적 압축**을 수행할 수 있는 토대가 됩니다.

## 3. 인코딩 및 압축 방식의 차이와 작동 원리

### Avro의 인코딩 및 압축
Avro는 **행 단위(row-based)** 저장 포맷으로, 각 레코드의 필드값들을 스키마에 따라 **순차적으로 이진 인코딩**합니다. Avro의 **이진 인코딩 규칙**은 스키마 타입별로 정의되어 있는데, 예를 들어 정수형은 **가변 길이 부호 있는 Zigzag 인코딩**으로 저장되고, 문자열은 **UTF-8 바이트 앞에 길이를 나타내는 zigzag int**를 붙여 저장하는 식입니다. 또한 배열이나 맵 같은 구조는 각 블록의 길이를 기록한 후 연속된 원소를 넣는 등 비교적 단순하지만 효율적인 방식으로 직렬화됩니다. 중요한 점은 **필드 이름이나 스키마 정보는 데이터에 포함하지 않는다**는 것인데, 이는 모두 헤더의 JSON 스키마에 있기 때문에, 데이터 섹션에서는 오직 **값들만 연속으로 나열**하여 공간 효율을 높입니다.

Avro 자체는 **특정 컬럼을 위한 특수 인코딩(dictionary, RLE 등)**을 하지 않고, **스키마 기반의 일반적인 이진 직렬화**를 합니다. 따라서 데이터 크기 압축은 주로 **블록 단위의 압축(codec)**에 의존합니다. Avro 파일은 헤더 메타데이터의 `"avro.codec"` 속성으로 압축 코덱을 지정할 수 있으며, 기본값은 `"null"`(압축 안 함)이고 `"deflate"`(Zlib), `"snappy"` 등의 옵션을 제공합니다. 압축 코덱이 지정되면, 앞서 설명한 **데이터 블록** 내 **레코드 데이터 부분** 전체에 대해 **블록 단위 압축**이 적용됩니다. 예를 들어 `"avro.codec": "deflate"`로 설정하면 각 블록의 레코드들을 모두 직렬화한 뒤 하나의 바이트 배열로 압축 저장하고, 블록 헤더에 압축 후 바이트 크기를 기록합니다.

이러한 Avro의 압축 방식은 **행 전체를 한 번에 압축**하는 형태이므로, 한 블록 안에 여러 타입의 필드 데이터가 섞여 있습니다. 그 결과 압축 알고리즘 입장에서는 **다양한 데이터 타입이 혼재**된 바이트열을 처리하게 되므로, **유사한 값이 연속되는 패턴**을 찾기가 상대적으로 어렵습니다. 압축률 측면에서 보면, Avro는 반복되는 패턴이 적은 **잡색의 데이터 스트림**을 블록 단위로 압축하므로, **컬럼식 압축보다 효율이 떨어질 수 있습니다**. 예를 들어 동일한 100만 행 데이터라 해도, Avro는 각 행(레코드)의 모든 필드가 섞여있는 상태에서 압축을 시도하는 반면, Parquet는 각 열마다 호Omogeneous한 값들만 모아 압축하기 때문에 더 높은 압축 비율을 얻는 경향이 있습니다.

다만 Avro는 기본적으로 **연속된 레코드의 중복**을 별도로 인코딩하지는 않지만, **스키마에 정의되지 않은 부분은 기록하지 않는** 최적화를 이미 갖추고 있습니다. 또한 Avro 블록 크기를 크게 하면(예: 한 블록에 수만~수십만 행) 비슷한 값들이 모일 확률이 높아져 압축 효과가 어느 정도 향상될 수 있습니다. **요약하면**, Avro는 **데이터 자체의 이진 표현을 간소화**하여 크기를 줄이고, **추가로 블록 전체를 압축**하는 두 단계로 공간 최적화를 합니다. 그 덕분에 Avro는 **직렬화/역직렬화 속도**가 빠르고 (필드별 간단한 decoding), 연속된 블록을 읽어들여 **즉시 레코드 단위**로 처리하기에 용이합니다. 하지만 **열 지향 인코딩 부재**로 인해 특정 컬럼만 압축하거나 건너뛰는 최적화는 불가능하므로, 후술할 Parquet에 비해 대규모 데이터 집합의 컬럼 분석 작업에서는 I/O 면에서 비효율적일 수 있습니다.

### Parquet의 인코딩 및 압축
Parquet의 큰 장점 중 하나는 **컬럼별 최적화된 인코딩과 압축**을 적용한다는 것입니다. Parquet는 **열 지향 저장**이므로, 각 컬럼(필드)의 데이터 특성에 따라 서로 다른 인코딩 기법을 사용하여 데이터 크기를 줄이고, 그 결과 압축 효율과 I/O 성능을 높입니다. 주요 인코딩 방식과 압축 기법은 다음과 같습니다:

- **플레인 인코딩(Plain Encoding)**: 별도의 최적화가 어려운 경우 기본적으로 쓰는 방식으로, 값을 있는 그대로 바이트로 표현합니다. 예를 들어 INT32는 4바이트 리틀엔디언, DOUBLE은 8바이트 IEEE 형식 등으로 고정 길이 저장합니다. 문자열(byte array)은 앞에 4바이트 길이를 붙이고 그만큼의 바이트를 저장합니다. Boolean은 1비트를 의미하지만 8개씩 모아 1바이트로 **비트 패킹**합니다. Plain은 데이터에 따라 이득은 없지만 모든 타입에서 지원됩니다.

- **딕셔너리 인코딩(Dictionary Encoding)**: **카디널리티(중복)**가 높은 문자열이나 카테고리컬(column의 고유값 종류가 적은) 데이터에 사용하는 방식입니다. 한 컬럼 청크 내에 등장하는 **고유한 값들만 모아 사전(dictionary) 테이블**을 만들고, 실제 데이터 페이지에는 각 값 대신 **사전의 인덱스(작은 정수)**를 저장합니다. 예를 들어 국가명이 들어있는 컬럼에 "Korea", "USA", "USA", "Korea", "France"가 있다면, ["Korea","USA","France"]를 사전으로 만들고 본문에는 [0,1,1,0,2]처럼 적습니다. 사전은 별도의 **dictionary page**에 Plain 인코딩으로 저장되고, 본문은 작은 정수이므로 메모리 차지가 크게 줄어듭니다. 딕셔너리는 **고유값이 너무 많아지면 효과가 떨어지므로**, 일정 임계치를 넘으면 자동으로 Plain 인코딩으로 전환합니다.

- **런-길이 인코딩(Run-Length Encoding, RLE)**: **연속 반복되는 값**들을 효율적으로 표현하는 기법입니다. 컬럼 형태로 저장하면 같은 값이 연이어 나오는 경우가 흔하므로, Parquet는 **값이 n번 반복된다**는 정보를 `<값, 반복횟수>` 형태로 기록합니다. 예를 들어 어떤 컬럼에 값이 `[A, A, A, A, B, B, C]`로 들어있다면, RLE 인코딩으로 `[("A",4),("B",2),("C",1)]` 같이 저장합니다. Parquet는 **딕셔너리 인코딩 후** 결과 값들(작은 정수들)에 다시 RLE를 적용하여, 예를 들어 `0,0,0,0,1,1,2` 같은 시퀀스를 `[(0,4),(1,2),(2,1)]`로 줄입니다. Parquet의 RLE는 효율을 위해 비트-패킹과 혼합된 하이브리드 방식을 사용하며, 짧은 반복은 비트패킹으로, 긴 반복은 RLE로 처리합니다.

- **델타 인코딩(Delta Encoding)**: 주로 **숫자나 시간 같이 값이 점진적으로 증가 또는 감소**하는 패턴에 사용됩니다. 연속된 값들 간의 **차분만 저장**하여 변동 폭이 작을 때 이득을 얻는 방식입니다. 예를 들어 시간 값 컬럼이 초 단위로 증가한다면, `[1609459200, 1609459260, 1609459320]` (UNIX time) 대신 첫 값과 이후 **증분 60, 60**만 저장하는 식입니다. 이렇게 하면 원래 값 자체보다 작은 숫자들로 기록되므로 추가 압축이 용이해집니다. Parquet는 `DELTA_BINARY_PACKED` 등 알고리즘으로 정수열에 대해 델타 인코딩을 제공합니다.

- **비트 팩킹(Bit-Packing)**: boolean이나 작은 범위의 숫자들을 연달아 저장할 때, 각 값을 정해진 비트수만큼 연속으로 붙여서 저장하는 기법입니다. 예컨대 0/1로만 이루어진 bool 열 8개를 한 바이트에 묶는 것이 비트패킹의 한 형태입니다. Parquet는 단독보다는 주로 RLE와 혼용하여 **RLE/비트패킹 하이브리드** 형태로 사용합니다.

Parquet 파일의 각 **페이지(Page)**에는 위 인코딩들 중 하나가 적용됩니다. 일반적으로 **한 컬럼 청크의 첫 페이지**는 해당 청크의 딕셔너리(만약 사용된다면)를 담고, 그 다음부터 데이터 페이지들이 나옵니다. 인코딩 유형은 컬럼 메타데이터에 기록되어 있어, 읽을 때 어떤 방식으로 복원(decode)해야 할지 알 수 있습니다.

인코딩 외에도 **압축 알고리즘**을 추가로 적용하여 저장 공간을 줄입니다. Parquet는 **열별 압축(codec)**을 지원하는데, 일반적으로 **Snappy**가 기본값으로 많이 사용됩니다. 그 외 Gzip, Brotli, LZ4 등의 코덱을 지정할 수 있습니다. 압축은 보통 **페이지 단위**로 수행되며, 인코딩을 마친 후의 바이너리 데이터를 다시 한번 압축해서 저장합니다. **컬럼 단위로 같은 타입의 데이터가 모여 있으므로 압축 효율이 높고**, 전체 데이터를 섞어서 압축하는 Avro보다 **동일 압축 알고리즘으로도 더 높은 압축률**을 보이는 경우가 많습니다. 실제로 Parquet와 Avro 모두 **Snappy 압축**을 지원하지만, Parquet 쪽이 **열 타입에 특화된 알고리즘 적용으로 동일 공간에 더 많은 데이터를 담을 수 있다**고 알려져 있습니다.

Parquet의 이러한 인코딩/압축 조합 덕분에 **IO 양을 크게 줄일 수 있고**, CPU를 써서 압축 해제하더라도 전체 성능이 향상되는 경우가 많습니다. 예를 들어 Twitter에서 Parquet를 초기 도입 시 **스토리지 사용량 28% 절감, 단일 컬럼 읽기 속도 90% 개선**을 달성했고, 이후 **컬럼 전용 압축, 사전압축, 비트팩, RLE** 등을 추가하여 **저장 공간 52% 추가 절감, 읽기 시간 48% 추가 감소**를 이루었다는 보고도 있습니다. 이처럼 Parquet는 **열 지향 인코딩**을 통해 **데이터 크기를 최소화**하고, 필요한 열만 읽는 **프로젝션 푸쉬다운**과 결합하여 **빅데이터 분석 쿼리를 가속화**합니다.

요약하면, Avro는 **전체 레코드를 일반 이진 형태로 저장**하고 블록 압축으로만 크기를 줄이는 반면, Parquet는 **컬럼별로 특화된 인코딩(RLE, 딕셔너리 등)**을 적용하고 추가 압축을 함으로써 **더 높은 압축률과 빠른 컬럼 조회**를 가능케 합니다. 이러한 차이는 두 포맷의 사용 목적과 성능 특성에 직접적인 영향을 미칩니다.

## 4. 주요 분석 도구에서의 사용 방식과 최적화 전략 (Spark, Hive, BigQuery 등)

### Apache Spark에서의 Avro와 Parquet
**Apache Spark**는 Parquet를 데이터소스의 기본 형식으로 채택할 만큼, Parquet에 대한 최적화 지원이 잘 되어 있습니다. Spark SQL엔진은 Parquet 파일을 읽을 때 **스키마를 자동 추론**하고, **컬럼 프루닝(column pruning)**과 **프레디킷 푸쉬다운(predicate pushdown)**을 수행합니다. 즉, 쿼리에서 필요한 컬럼들만 디스크에서 읽고, 필터 조건에 맞지 않는 Row Group은 아예 읽지 않도록 건너뜁니다. Spark는 Parquet를 읽을 때 **벡터화된 I/O**를 사용하여 한 번에 다수의 값(batch)을 메모리에 로드하고 처리하므로, JVM GC 부하를 줄이고 CPU 효율을 높입니다. 또한 Spark는 기본적으로 Parquet에 **압축 코덱 Snappy**를 사용하여 성능과 압축 균형을 취합니다 (설정으로 `spark.sql.parquet.compression.codec` 변경 가능). **데이터 파티셔닝**도 일반적으로 Parquet와 함께 활용되는데, 예를 들어 날짜별 디렉토리로 파일을 분할 저장하면 Spark는 쿼리 시 해당 파티션 경로만 읽어들여 I/O를 줄입니다. Parquet의 메타데이터에는 컬럼별 통계(최솟값/최댓값)가 포함되므로, **Spark는 일부 조건에 대해 Parquet Row Group 단위 필터링** 최적화도 수행합니다 (버전에 따라 min/max 푸쉬다운).

Spark에서 **Avro** 파일도 지원되며, Spark 2.4부터는 Avro 데이터소스가 기본 내장되었고 그 이전에는 `spark-avro` 패키지로 외부 지원했습니다. Avro 파일을 읽을 때는 `spark.read.format("avro").load(path)`를 사용하고, 쓰기는 `df.write.format("avro").save(path)` 형식으로 수행합니다. Avro는 파일에 스키마가 내장되어 있으므로 Spark가 자동으로 스키마를 인식하는 장점이 있습니다. 다만 Avro는 **행 지향**이라 Spark가 읽을 때 **모든 필드를 한 번에 역직렬화**해야 하므로, Parquet처럼 필요한 컬럼만 부분적으로 읽는 것은 구조적으로 불가능합니다. 즉, **컬럼 프루닝은 Avro의 경우 파일 레벨에서 작동하지 않고** Spark 엔진이 레코드 전체를 가져와서 내부적으로 필요한 컬럼만 사용하게 됩니다. 이는 넓은 스키마에서 일부 컬럼만 사용하는 쿼리의 경우 **불필요한 I/O와 역직렬화 비용**이 발생함을 의미합니다.

Spark에서 Avro를 쓸 때 **압축 설정** 역시 가능하며, 옵션으로 `compression`을 지정하거나 Spark SQL 설정 `spark.sql.avro.compression.codec`을 사용해 Deflate, Snappy 등을 적용할 수 있습니다. 그러나 Avro 블록 단위 압축은 Parquet의 열 압축만큼 세밀하게 튜닝되지는 않습니다. Avro는 대신 **빠른 쓰기 성능**과 **스키마 유연성**으로 Spark ETL 파이프라인의 중간 저장 포맷이나 Kafka 등의 스트리밍 입출력에서 애용됩니다. Spark Streaming이나 Structured Streaming으로 처리한 데이터를 Avro로 싱크 저장하면, 나중에 그 Avro 파일들을 Spark로 다시 읽어와 DataFrame으로 활용할 수 있습니다. 

**정리:** Spark에서는 Parquet가 **최적화(컬럼별 I/O 및 벡터화)** 덕분에 대화형 쿼리나 대규모 집계에 뛰어난 성능을 보입니다. Avro는 Spark에서 주로 **데이터 interchange 및 로깅**에 사용되고, 전체 레코드를 다루는 작업에 쓰이며, Parquet만큼의 쿼리 최적화는 어렵지만 **Write 성능과 스키마 관리 용이성** 측면에서 유용합니다. Spark 애플리케이션에서는 필요에 따라 Avro로 빠르게 데이터 수집을 한 다음, 최종 분석 전에 Parquet로 변환하여 저장하는 패턴도 흔합니다.

### Apache Hive에서의 Avro와 Parquet
**Apache Hive**는 테이블의 저장 포맷으로 Avro와 Parquet 모두를 지원합니다. Hive는 내부적으로 **SerDe**(Serializer/Deserializer)를 통해 특정 파일포맷을 테이블로 매핑하는데, Avro용 **AvroSerDe**와 Parquet용 **ParquetSerDe**가 제공됩니다.

**Hive와 Avro:** Hive 0.14 버전부터는 DDL에서 `STORED AS AVRO` 구문으로 간단히 Avro 테이블을 생성할 수 있습니다. 그 이전 버전이나 세부 제어가 필요한 경우, `ROW FORMAT SERDE 'org.apache.hadoop.hive.serde2.avro.AvroSerDe'` 및 `STORED AS ... AvroContainerInputFormat/OutputFormat`을 명시하고, `TBLPROPERTIES('avro.schema.url'='hdfs://.../schema.avsc')`와 같이 Avro 스키마 위치를 지정하는 방식으로 테이블을 정의합니다. Avro 테이블 생성 시 **스키마 정의**가 필수인데, 위처럼 **외부 `.avsc` 파일 경로**를 제공하거나 `avro.schema.literal`에 JSON 스키마를 직접 넣을 수 있습니다. 한편 Avro 데이터 파일 자체에 스키마가 들어 있으므로, **Hive 외부 테이블로 Avro 데이터를 등록**할 때는 Hive가 자동으로 파일의 스키마를 읽어오도록 할 수도 있습니다 (단, Hive 버전에 따라 명시적 스키마 지정이 필요할 수 있음).

Hive에서 Avro 테이블을 조회하면, **AvroSerDe가 각 파일의 헤더에서 스키마를 읽어와 레코드를 역직렬화**합니다. Avro는 인덱스나 통계정보가 파일 내에 없기 때문에, **Hive는 파티션 단위 이외에는 Avro 파일의 내부에서 범위를 건너뛰는 최적화가 어렵습니다**. 즉, Hive가 Avro 테이블에 `WHERE`절을 걸어 조회하면, 해당 파티션의 모든 Avro 레코드를 순차 스캔하면서 조건에 맞는지 검사합니다. 이때 Hive MapReduce나 Tez 작업으로 분산 처리 시, Avro sync 마커를 활용하여 **대용량 파일을 병렬 처리**하는 것은 가능하지만, **컬럼 단위의 I/O 절감은 불가**합니다. 따라서 Hive에서 Avro는 주로 **데이터 호환성과 스키마 유연성**이 필요할 때 사용되며 (예: 여러 스키마 버전의 데이터를 한 테이블로 관리), **고속의 분석 쿼리**에는 적합하지 않을 수 있습니다. 장점은 Hive가 AvroSerDe를 통해 **복잡한 Avro 구조 (레코드의 중첩, 맵, 배열 등)**도 Hive의 STRUCT, MAP, ARRAY 등으로 매핑하여 SQL로 다룰 수 있다는 점입니다.

**Hive와 Parquet:** Parquet는 Hive 0.13 즈음부터 공식 지원되었으며, DDL에서 `STORED AS PARQUET`으로 설정합니다. Hive의 ParquetSerDe는 테이블 스키마에 따라 Parquet의 스키마를 생성하거나, 외부 테이블이면 Parquet 파일의 스키마를 읽어옵니다. Hive에서 Parquet 테이블을 조회하면, **각 Mapper(또는 Tez Task)가 Parquet 푸터 메타데이터를 읽어 필요한 컬럼만 로드**합니다. Hive는 또한 **Partition Pruning**을 수행하고, 파티션 내에서 Parquet의 **Row Group 통계(min/max)**를 이용한 **프레디킷 푸쉬다운**도 어느 정도 지원합니다. 비록 ORC처럼 강력한 인덱싱(스트라이프 내 인덱스)이 Parquet에는 없지만, Hive는 **파일 단위 메타데이터 캐시**(LLAP나 Hive3의 다이렉트 리더) 등을 통해 Parquet 쿼리를 최적화할 수 있습니다. 특히, Hive 3.x 이후에는 `HiveWarehouseConnector`나 LLAP을 통해 Parquet를 벡터화 읽기하여 성능을 향상시켰습니다.

Parquet 테이블은 Hive에서 **INSERT OVERWRITE** 등을 통해 데이터를 쓰면 자동으로 Parquet 포맷으로 저장됩니다. Hive는 데이터를 쓸 때 **테이블 스키마와 Parquet 스키마를 자동 매핑**해주므로 사용자가 직접 Parquet 쓰기 코드를 짤 필요가 없습니다. Hive에서 Parquet의 장점은 저장 공간 절약과 읽기 성능으로, ORC와 비교해도 대등한 수준의 압축과 쿼리 효율을 보입니다. (ORC는 Hive 최적화에 특화되어 약간 더 나은 통계 인덱싱을 가지지만, Parquet도 임팔라/스파크 등 범용 생태계 장점이 있어 Hive에서도 충분히 활용됩니다.)

**정리:** Hive에서 Avro는 **스키마 관리의 유연함**과 **다양한 데이터 형태 지원**을 이유로 사용되며, 데이터 레이크에서 중간 포맷이나 원본 로그 보관 등에 쓰입니다. Parquet는 Hive의 **데이터 웨어하우스 테이블**에 많이 사용되며, **대용량 배치 쿼리나 BI 쿼리**에서 성능상 이점을 줍니다. Hive 테이블을 설계할 때, **실시간 변동이 많은 데이터**나 **스키마 변경 가능성**이 있는 경우 Avro로, **집계 위주 분석 데이터**는 Parquet로 선택하는 전략을 취할 수 있습니다.

### Google BigQuery에서의 Avro와 Parquet
**Google BigQuery**는 완전관리형 데이터웨어하우스 서비스로, Avro와 Parquet 포맷의 데이터를 모두 지원하지만 그 사용 방식에는 차이가 있습니다.

- **데이터 로딩 (적재) 측면:** BigQuery는 외부 저장소(GCS)에 있는 Avro 또는 Parquet 파일을 **네이티브 테이블로 로드**할 수 있습니다. 이때 **BigQuery 엔진 내부적으로 포맷 변환**이 일어나며, 최종적으로 BigQuery의 컬럼 지향 저장인 Capacitor 포맷으로 저장됩니다. **성능 관점에서**, Avro나 Parquet나 **로드 시간은 비슷한 편**이라고 알려져 있습니다. 다만, BigQuery 팀은 **일부 상황에서 Avro가 Parquet보다 적재가 빠른 경우**도 있다고 언급했습니다. 예를 들어, Cloud Dataflow에서 BigQuery로 데이터를 내보낼 때 JSON 대신 Avro를 사용함으로써 **약 10배의 로딩 성능 개선**을 얻었다는 사례가 있습니다. 이는 Avro가 한 레코드를 하나의 연속된 바이너리로 인코딩하므로 BigQuery가 파싱하기 수월하고, 스키마를 한 번만 처리하면 되기 때문입니다. 반면 Parquet는 컬럼 분할+압축으로 인해 BigQuery가 로드 시 **각 컬럼을 해제압축 및 재조합**해야 하므로 약간의 오버헤드가 있을 수 있습니다. 실제로 BigQuery 엔지니어인 Mosha Pasumansky는 *"Parquet 로딩은 Avro보다 느릴 수 있다"*고 언급한 바 있습니다. 따라서 **대용량 배치 적재**를 최적화하려면 Avro로 준비하는 것이 유리할 수 있습니다. 하지만 이 차이는 경우에 따라 미미하며, 병렬 로드나 네트워크 제약 등 다른 요소의 영향도 큽니다.

- **쿼리 및 외부 테이블 측면:** BigQuery는 GCS 상의 Avro/Parquet 파일에 대해 **외부 테이블**을 정의하여 직접 쿼리할 수 있습니다 (Federated Query라고도 불림). **외부 테이블**로 Avro를 사용할 경우, BigQuery는 각 Avro 파일의 스키마를 읽어와 스키마를 파악하고, 쿼리 시 **전체 레코드 단위**로 스캔합니다. Parquet 외부 테이블의 경우, BigQuery는 Parquet 메타데이터를 활용해 **필요한 컬럼만 읽어오는 최적화**를 수행합니다. 이는 BigQuery가 Parquet 파일을 다룰 때, 실제로 해당 컬럼의 바이트만 GCS에서 가져오도록 최적화되었음을 의미합니다. 결과적으로 **넓은 테이블에서 일부 컬럼만 조회하는 쿼리**라면, Parquet 외부 테이블이 Avro 외부 테이블보다 **네트워크 I/O 및 처리량 측면에서 효율적**입니다. 반면 **전체 레코드를 자주 삽입/읽는 패턴**에서는 Avro도 손쉽게 사용할 수 있습니다.

BigQuery는 **Avro와 Parquet 모두 중첩된 구조와 복합 데이터 타입**을 지원합니다. Avro의 네이티브 레코드/배열/맵 타입은 BigQuery의 STRUCT/ARRAY로 매핑되고, Parquet의 중첩 필드(Definition/Repetition Level로 표현된) 역시 잘 매핑됩니다. 특히 Avro는 **Union**을 지원하여 필드를 `[null, "type"]` 형태로 Optional 취급할 수 있는데, BigQuery에서 NULL 가능 필드로 읽힙니다. Parquet도 필드를 optional로 지정하면 BigQuery에서 NULL을 허용하는 필드가 됩니다. 따라서 **데이터 표현력 측면**에서는 두 포맷 모두 BigQuery에 손실 없이 적재가 가능합니다.

**사용 방식 예시:**  
- *적재*: GCS에 `data.avro`들이 있을 때 `bq load --source_format=AVRO dataset.table gs://bucket/path/*.avro` 명령으로 일괄 로드합니다. Parquet일 경우 `--source_format=PARQUET`로 지정하면 됩니다. 이때 Avro는 스키마가 파일에 있으므로 별도 스키마 정의가 필요없고, Parquet도 파일 내 스키마로부터 자동 스키마 유추가 가능합니다.
- *외부 테이블*: BigQuery SQL에서  
  ```sql
  CREATE EXTERNAL TABLE dataset.ext_table
  WITH CONNECTION `project.location.connections.gcs_conn`
  OPTIONS(
    format = 'PARQUET',
    uris = ['gs://bucket/path/*.parquet']
  );
  ```  
  와 같이 Parquet 외부 테이블을 만들 수 있습니다. Avro도 format만 'AVRO'로 바꾸어 비슷하게 정의합니다. 그런 다음 `SELECT * FROM dataset.ext_table WHERE ...`로 쿼리하면, BigQuery가 실시간으로 GCS 파일을 읽어 결과를 반환합니다. 이 경우 앞서 언급한 컬럼 읽기 최적화가 적용됩니다.

**최적화 관점:** BigQuery는 완전관리형이므로 사용자가 파일 내부 구조를 최적화할 여지는 적지만, **적절한 포맷 선택과 파일 크기 관리**가 중요합니다. 예를 들어 **수억 건의 작은 JSON보다는 Avro나 Parquet로 배치 묶어** 두는 것이 로드 성능과 스토리지 비용에 유리합니다. Avro는 **블록 크기**(기본 64MB 정도)와 압축 코덱(예: Deflate 수준)을 조절하여 로드 성능을 미세 조정할 수 있고, Parquet는 **Row Group 크기**(예: 128MB)와 압축(codec) 설정을 통해 BigQuery 외부 쿼리 시 큰 파일 단위로 처리되도록 조정할 수 있습니다.

**정리:** BigQuery 환경에서 Avro와 Parquet는 주로 **데이터 교환 및 적재 포맷**으로 쓰입니다. **일회성 로드**나 **데이터 파이프라인 중간결과 전달**에는 Avro가 간편하고 빠른 선택일 수 있고, **장기 보관하거나 외부 테이블로 분석**할 데이터에는 Parquet가 유리할 수 있습니다. 두 포맷 모두 BigQuery에서 기본적으로 지원하므로, **상황에 따라 최적 포맷**을 선택하여 GCS에 데이터를 준비하고 BigQuery로 불러오는 전략을 취합니다.

## 5. 어떤 상황에서 어떤 포맷을 선택해야 하는지 (심층 비교)

Avro와 Parquet는 각각 **장단점과 최적 용도**가 다르므로, 사용 시나리오에 따라 적합한 포맷을 선택하는 것이 중요합니다. 두 포맷을 다양한 측면에서 비교하고, 어떤 상황에 어느 포맷이 더 유리한지 살펴보겠습니다.

- **데이터 액세스 패턴**: Avro는 **행 기반(row-oriented)**이므로, **전체 레코드**를 자주 읽고 쓰는 워크로드에 최적입니다. 예를 들어 **OLTP(온라인 트랜잭션 처리)**나 **실시간 로그 수집**처럼 하나의 이벤트(레코드)를 완전히 기록하고 다시 그대로 재현해야 하는 경우 Avro가 적합합니다. Parquet는 **열 기반(column-oriented)**이므로, **대량의 데이터에서 일부 컬럼만 조회하거나 집계하는** **OLAP(온라인 분석 처리)** 쿼리에 뛰어난 성능을 냅니다. 즉, 수십 컬럼 중 2~3개만 참조하는 쿼리, 테라바이트 규모 데이터에서 집계를 구하는 분석 등에는 Parquet가 월등한 속도를 보입니다. **요약**: **쓰기/읽기 균형과 레코드 단위 접근**이 중요하면 Avro, **읽기 중심과 컬럼 단위 대량처리**가 중요하면 Parquet입니다.

- **스키마 진화 및 유연성**: Avro는 처음부터 **스키마 진화(schema evolution)**를 핵심 특징으로 설계하여, **전/후방 호환** 스키마 변경에 강합니다. 필드를 추가하더라도 기본값을 지정하면 옛 데이터와 호환되고, 필드 제거나 타입 변경도 호환 규칙 내에서 가능합니다. 또한 Avro는 데이터를 쓸 때 **Writer의 스키마**와 읽을 때 **Reader의 스키마**를 분리해서, 서로 다른 스키마 버전 간 데이터 교환을 지원합니다. Parquet도 기본적으로 **스키마를 파일에 저장**하지만, 여러 파일로 이루어진 테이블에서 스키마 변경을 관리하는 것은 전적으로 상위 메타스토어(Hive Metastore나 Iceberg 같은 테이블 포맷)에 맡깁니다. Parquet 자체도 컬럼 추가 등의 변경은 허용(새 컬럼은 기존 파일에 없으면 null 처리)되므로 진화 가능하나, Avro만큼 **명시적이고 세밀한 호환성 규칙**을 제공하지는 않습니다. 따라서 **스키마가 자주 바뀌는 이벤트 로그 파이프라인**이나 **다양한 스키마 버전의 데이터 혼재** 상황에서는 Avro가 관리하기 수월합니다. 반대로 **한 번 정의되면 잘 변하지 않는 데이터 모델**(예: 데이터 웨어하우스의 사실/차원 테이블)에는 Parquet가 적합하며, 이 경우 큰 문제 없이 테이블 스키마 확장이 가능합니다.

- **파일 크기와 저장 공간**: 동일한 데이터라면, 일반적으로 **Parquet 파일 크기가 Avro보다 작습니다**. Parquet의 열 단위 압축과 인코딩 덕분에, 특히 **값 중복이 많거나 숫자/카테고리 데이터가 많은 경우** 높은 압축률을 보입니다. Avro는 블록 압축만으로는 Parquet만큼 줄이지는 못하나, 그 대신 작은 레코드도 부담없이 기록할 수 있습니다. **작은 파일 시나리오**를 비교해 보면, Avro는 몇 KB~MB 단위 소규모 파일에서도 헤더+동기화 마커 오버헤드가 수십 바이트 수준이라 영향이 적습니다. 반면 Parquet는 푸터에 메타데이터와 통계 등을 가지므로, 너무 작은 파일 수천 개로 쪼개지면 오히려 메타데이터 오버헤드 비중이 커지고, 압축 효율도 떨어집니다. 따라서 **소규모 파일이 많은 워크로드**(예: IoT 센서별 로그 등)에서는 Avro로 수집 후 나중에 병합하는 것이 좋고, **일정 크기 이상으로 배치 묶을 수 있는 데이터**(예: 시간 단위 파티션)에는 Parquet로 저장해 두는 것이 효율적입니다.

- **쓰기 성능 vs. 읽기 성능**: Avro는 **쓰기 성능이 우수**합니다. 레코드를 받아 바로바로 이어쓰기(append)가 가능하고, 복잡한 버퍼링이 필요없으며, 한 레코드씩 지속적으로 추가해도 큰 문제가 없습니다. 반면 Parquet는 **Row Group이 완성될 때까지 데이터와 메타정보를 메모리에 모아두었다가** 한 번에 기록하는 패턴이기 때문에, **실시간 증분 쓰기에는 부적합**합니다. 예를 들어 Kafka Connect로 실시간 스트림을 HDFS에 쓸 때 Avro는 레코드가 생길 때마다 flush할 수 있지만, Parquet로 매 건마다 flush하면 쓸모 없는 작은 Row Group이 양산됩니다. Parquet는 배치처리에서 일정량(예: 수만 행)을 모아서 쓰는 경우에 최적이며, 이 때의 쓰기 부하(인코딩/압축)는 높지만 이후 **읽기 성능 이득**으로 보상받습니다. 읽기 측면에서는, Parquet는 원하는 열만 골라 읽을 수 있어 디스크 I/O와 네트워크 사용량을 절감하고, Avro는 행 단위로 모두 읽어야 해서 데이터량이 클수록 불리합니다. 따라서 **주로 Write-heavy, Write-once/Read-few** 패턴(예: 로그 수집, 이벤트 스트림)엔 Avro, **Read-heavy** 패턴(질의·분석 중심)엔 Parquet가 최적화되어 있습니다.

- **데이터 프로세싱 및 호환성**: Avro는 **언어 중립적**인 데이터 직렬화 프레임워크로, 다양한 언어에서 바로 Avro 포맷으로 직렬화하여 데이터를 주고받는 데 활용됩니다. 예컨대 Python에서 Avro로 직렬화해 놓은 데이터를 Java 서비스에서 역직렬화하는 식으로, **시스템 간 인터페이스** 용도로도 쓰입니다. 또한 Avro는 **RPC** 기능도 스펙에 포함하고 있어 마이크로서비스 통신에 Avro 프로토콜을 쓰는 경우도 있습니다. 반면 Parquet는 **분석용 컬럼 포맷**으로 시작하여 주로 **Hadoop/Spark SQL 엔진들**에서 소비되는 용도로 발전해왔습니다. Parquet 파일을 직접 읽을 일이 있는건 대개 분석 도구(Python Pandas 등)나 SQL엔진을 통해서입니다. 따라서 **데이터 lake에 저장 후 여러 도구로 쿼리**하기에는 Parquet가 널리 지원되어 좋고, **한 번 쓰인 데이터를 여러 언어 프로그램에서 처리**해야 하거나 **메시지 버스(Kafka 등)로 전달**해야 한다면 Avro가 자연스러운 선택입니다.

- **예외 및 기타 고려사항**: 
  - **압축 형태**: Avro는 Deflate 사용시 압축률은 높지만 CPU 사용이 커져 실시간성에 불리할 수 있고, Snappy는 빠르나 압축률이 낮습니다. Parquet는 기본 Snappy로도 칼럼 특성 때문에 Avro/Deflate만큼 압축되거나 더 나은 경우가 많습니다. 그리고 Parquet는 ZSTD/Brotli 같은 최신 알고리즘도 지원해 저장 최적화 폭이 큽니다.
  - **복잡한 스키마 데이터**: 둘 다 중첩 필드를 다루지만, Avro는 **맵, 유니온(union)** 타입 등이 자연스러워 JSON 유사 데이터를 손쉽게 묘사합니다. Parquet도 지원은 하지만 완전히 자유로운 유니온은 없고 (옵셔널 필드로 처리), 맵은 키-값 구조로 변환되어 저장됩니다. JSON 같은 반정형 데이터를 저장할 때 Avro가 개념적으로 더 직관적일 수 있습니다. 그러나 Parquet도 Arrow 프로젝트 등을 통해 JSON to Parquet 변환이 일상적이므로 큰 문제는 아닙니다.
  - **Eco-system**: Avro는 Confluent Schema Registry 등과 통합되어 **스트리밍 플랫폼**에서 표준처럼 쓰입니다. Parquet는 Spark, Trino(Presto), Hive, Impala, Drill, Flink 등 **배치/대화형 엔진**의 표준으로 인식됩니다. 자신의 기술 스택에 어느 포맷 지원이 더 성숙한지 고려해 선택할 수 있습니다.

**심층 비교 결론:** Avro와 Parquet 모두 빅데이터 환경에서 필수적인 **오픈 파일 포맷**이며, 함께 사용되는 보완적 관계인 경우가 많습니다. **Avro는 빠른 처리와 스키마 유연성을 무기로 데이터 수집/교환 단계**에서 활약하고, **Parquet는 뛰어난 압축도와 쿼리 성능으로 데이터 저장/분석 단계**를 책임집니다. 일반적으로 **"브론즈(원시 데이터) 레이어에는 Avro, 실버/골드(정제/최적화 데이터) 레이어에는 Parquet"** 같은 계층적 전략도 쓰입니다. 결국 선택은 **Use Case**에 따라 달라지며, 
  - **실시간 처리 vs. 대화형 분석**, 
  - **스키마 빈번 변화 vs. 안정**, 
  - **다양한 시스템 호환 vs. 빅데이터 툴 최적화**, 
  - **쓰기 빈도 vs. 읽기 빈도** 
등을 기준으로 판단하게 됩니다. 두 포맷 모두 **스키마를 포함**하고 **스플릿/병렬처리 지원**, **대용량 처리에 검증된 포맷**이라는 **공통 장점**도 있으므로, 환경에 맞게 병행 활용하는 것도 고려해볼 만합니다.

## 6. AVRO와 Parquet 예제 파일 구조와 쿼리 예시

마지막으로, Avro와 Parquet을 실제로 사용하는 간단한 예시를 통해 앞서 설명한 내용을 확인해보겠습니다. Python, Spark, Hive, BigQuery 등 각기 다른 환경에서의 활용 예를 포함합니다.

### Avro 예제: Python과 Hive에서의 사용
**Python에서 Avro 파일 작성/읽기**: Python에서는 `fastavro` 라이브러리를 통해 Avro를 다룰 수 있습니다. 아래는 Avro 스키마를 정의하고 데이터를 파일로 기록한 후 다시 읽는 예시입니다 (의사코드): 

```python
import fastavro

# 1. Avro 스키마 정의 (JSON 형태)
schema = {
    "name": "User",
    "type": "record",
    "fields": [
        {"name": "username", "type": "string"},
        {"name": "age", "type": "int"},
        {"name": "verified", "type": "boolean", "default": False}
    ]
}

# 2. 예제 데이터 (파이썬 딕셔너리 리스트)
records = [
    {"username": "alice", "age": 30, "verified": True},
    {"username": "bob", "age": 25}  # verified 필드는 기본값 False 적용
]

# 3. Avro 파일 쓰기
with open("users.avro", "wb") as out:
    fastavro.writer(out, schema, records)

# 4. Avro 파일 읽기
with open("users.avro", "rb") as fo:
    reader = fastavro.reader(fo)
    for record in reader:
        print(record)
# 출력:
# {'username': 'alice', 'age': 30, 'verified': True}
# {'username': 'bob', 'age': 25, 'verified': False}
```

위 코드에서는 `schema`에 JSON으로 레코드 스키마를 정의하고, 두 개의 레코드를 Avro 포맷으로 파일에 저장했습니다. Avro 파일 `users.avro`를 보면 헤더에 스키마(JSON 문자열)와 `avro.codec` 등이 들어가며, 데이터 블록에 두 레코드의 바이너리 표현이 포함됩니다. 읽을 때는 fastavro가 파일의 헤더 스키마를 참고하여 Python 딕셔너리로 자동 변환해줍니다. (`verified`의 두 번째 레코드는 기록되지 않았지만 스키마 기본값으로 False가 채워진 것을 볼 수 있습니다 – **스키마 진화/기본값** 예시).

**Hive에서 Avro 테이블 생성 및 쿼리**: 앞서 Hive 파트에서 설명한 Avro 테이블을 실제로 만들어보겠습니다. Avro 스키마 파일 (`user.avsc`)이 HDFS에 업로드되어 있다고 가정하고, Hive CLI에서 다음과 같이 실행합니다:

```sql
CREATE EXTERNAL TABLE users_avro
ROW FORMAT SERDE 'org.apache.hadoop.hive.serde2.avro.AvroSerDe'
STORED AS AVRO
LOCATION '/data/users_avro/'
TBLPROPERTIES (
  'avro.schema.url'='hdfs://namenode:9000/schemas/user.avsc'
);
```

위 DDL은 `/data/users_avro/` 경로에 있는 Avro 파일들을 하나의 테이블로 매핑합니다. `user.avsc` 파일에는 해당 테이블의 Avro 스키마(JSON)가 정의되어 있습니다. 이제 이 테이블에 대해 쿼리를 수행해보겠습니다:

```sql
SELECT username, age 
FROM users_avro
WHERE verified = true;
```

Hive는 AvroSerDe를 사용하여 `/data/users_avro/` 밑의 Avro 파일들을 읽고 (`user.avsc` 스키마에 따라), `verified` 필드가 true인 사용자들의 `username`과 `age`를 반환할 것입니다. 내부적으로 MapReduce 작업이 뜰 수 있으며, Avro 파일의 sync 마커를 이용해 병렬 처리됩니다. 

Avro 테이블은 Spark에서도 읽을 수 있습니다. Spark SQL에서는 Hive 메타스토어 연동 시 위 테이블을 찾을 수 있고, 혹은 바로 DataFrame API로 Avro 파일을 읽을 수도 있습니다:

```scala
// Spark Scala 예제
val df = spark.read.format("avro").load("/data/users_avro/")
df.createOrReplaceTempView("users_avro_temp")
spark.sql("SELECT username, age FROM users_avro_temp WHERE verified = true").show()
```

Spark는 Hive와 마찬가지로 AvroSerDe를 통해 데이터를 가져오지만, Avro는 컬럼 푸쉬다운이 안되므로 `verified = true` 조건을 **후처리 필터링**하게 될 것입니다.

### Parquet 예제: Spark와 BigQuery에서의 사용
**Spark에서 Parquet 다루기**: Spark에서는 Parquet 지원이 기본이므로 매우 간단하게 사용할 수 있습니다. 예를 들어 위에서 Avro로 저장했던 같은 데이터셋을 Parquet로 저장하려면:

```python
# PySpark 예제
df = spark.createDataFrame(records)       # 앞에서 정의한 records 리스트를 DataFrame으로
df.write.mode("overwrite").parquet("/data/users_parquet/")
```

이렇게 하면 `/data/users_parquet/` 경로에 Parquet 파일이 생성됩니다. Spark는 자동으로 스키마를 인퍼하며, Parquet 파일 헤더에 스키마를 기록해둡니다. 이제 이 데이터를 불러와서 쿼리해보겠습니다:

```python
parquet_df = spark.read.parquet("/data/users_parquet/")
parquet_df.printSchema()
# root
#  |-- username: string (nullable = true)
#  |-- age: integer (nullable = true)
#  |-- verified: boolean (nullable = true)

parquet_df.createOrReplaceTempView("users_parquet")
spark.sql("SELECT username, age FROM users_parquet WHERE verified = true").show()
```

Spark의 `printSchema()` 출력에서 볼 수 있듯이, Parquet 파일의 스키마가 DataFrame에 반영되며 각 필드 타입이 보입니다. `SELECT username, age FROM ... WHERE verified = true` 쿼리를 실행하면 Spark는 Parquet 메타데이터를 사용하여 `verified` 열의 true 값이 있는 Row Group만 읽거나, 또는 최소한 `username`과 `age` 두 컬럼만 디스크에서 읽습니다. 결과로 조건을 만족하는 사용자들의 이름과 나이를 출력할 것입니다. 작은 예제라 체감하기 어렵지만, 수백 GB 데이터 중 극히 일부 컬럼만 요청한다면 **Spark는 Parquet의 컬럼 I/O 장점을 극대화**하여 Avro 대비 훨씬 빠르게 결과를 줄 것입니다.

Spark는 또한 **Partitioning**과 Parquet을 연계하여 성능을 높입니다. 예를 들어 사용자 데이터를 국가코드(country)별 폴더로 분할 저장하면, `WHERE country = 'KR'` 같은 조건시 해당 폴더(파일)만 읽는 Partition Pruning이 일어납니다. Avro도 Hive 등에서 디렉토리 파티셔닝은 가능하지만, Spark에서는 Parquet 파티션을 읽을 때 메타정보로 pruned RDD를 만들어 더욱 효과적으로 활용합니다.

**BigQuery에서 Parquet 외부 테이블 쿼리**: GCP 환경에서, 만약 위 `/data/users_parquet/`의 Parquet 파일을 GCS에 옮겼다고 가정하면, BigQuery에서 이를 곧바로 조회할 수 있습니다. 예를 들어 `gs://mybucket/users_parquet/part-00001-....parquet` 라는 파일이 있다면, BigQuery UI 혹은 CLI에서 아래와 같이 외부 테이블을 만들 수 있습니다:

```sql
CREATE EXTERNAL TABLE mydataset.users_parquet_ext
OPTIONS(
  format = 'PARQUET',
  uris = ['gs://mybucket/users_parquet/*.parquet']
);
```

이제 BigQuery에 연결된 외부 테이블 `users_parquet_ext`가 생성되었고, 스키마는 Parquet 파일에 기반하여 (`username: STRING, age: INT64, verified: BOOLEAN`) 설정되었을 것입니다. 여기에 질의를 해봅니다:

```sql
SELECT username, age
FROM mydataset.users_parquet_ext
WHERE verified = true;
```

BigQuery는 해당 Parquet 파일의 메타데이터를 읽어 `verified` 컬럼의 위치를 파악한 후, 조건에 해당하는 Row Group 혹은 페이지를 가려내어 필요한 부분만 읽습니다. (만약 Parquet에 min/max 통계가 있어 true/false 전부 포함하는지 알 수 있다면 일부 최적화 가능하겠지만, boolean이므로 그냥 전체 컬럼은 읽을 수도 있습니다.) 그래도 **username, age 컬럼 데이터만 전송**받기 때문에, Avro였다면 전체 레코드를 모두 스캔해야 하는 상황에서 Parquet 외부 테이블은 효율적으로 작동합니다.

**BigQuery에 Parquet 직접 로드**: 외부 테이블이 아니라 **네이티브 테이블로 적재**하는 경우, `bq load` 명령이나 Cloud Console에서 테이블 만들기로 Parquet 파일을 지정하면, BigQuery 내부적으로 데이터를 컬럼별 분산 저장소에 기록합니다. 사용자는 포맷 차이를 느끼지 못하지만, **대규모 배치 적재 시 Avro vs Parquet의 속도 차이**가 앞서 언급했듯 존재할 수 있습니다. 만약 수천 개의 파일을 로드한다면, Avro가 유리할 수 있으므로 상황에 따라 포맷을 미리 변환해두기도 합니다.

### 정리 및 추가 팁
- **압축 설정**: Avro 파일을 다룰 때 Python `fastavro`에서는 `compression` 파라미터로 'snappy'나 'deflate'를 지정할 수 있고, Spark에서는 `.option("compression","snappy")` 등으로 지정 가능합니다. Parquet는 Spark/Pandas 등에서 기본 Snappy지만 'gzip' 등으로 변경 가능하며, Hive에서도 `tblproperties("parquet.compress"="GZIP")` 등 설정이 있습니다.
- **스키마 호환**: Avro로 저장된 구버전 데이터와 신버전 스키마를 Spark나 Hive에서 매핑할 때, 호환성 문제가 생길 수 있습니다. 이 경우 Reader 스키마를 명시(예: Spark `avroSchema` option)하거나, Hive `avro.schema.literal`을 최신으로 주는 등 조정이 필요합니다.
- **파일 병합**: 작은 Avro 파일들은 MapReduce CombineFileInputFormat 등을 통해 처리할 수 있지만, Parquet의 경우 너무 잘개 쪼개져 있으면 성능 저하가 큽니다. 따라서 주기적으로 소량 파일을 합쳐 더 큰 Parquet 파일로 만드는 **Compaction 작업**이 필요할 수 있습니다.

以上의 예제와 설명을 통해 Avro와 Parquet 포맷의 구조, 동작 원리, 그리고 실제 사용상의 고려사항을 자세히 살펴보았습니다. Avro는 **스키마 중심의 경량 이진 포맷**으로서 **유연하고 빠른 쓰기/다양한 언어 호환**이라는 강점을, Parquet는 **컬럼 저장 기반의 고효율 포맷**으로서 **뛰어난 읽기 최적화/압축**의 강점을 가지고 있음을 알 수 있습니다. **자신의 빅데이터 워크로드 특성에 맞추어 두 포맷을 적재적소에 선택**하거나, **파이프라인 단계별로 혼용**함으로써 저장소와 분석 성능을 모두 최적화할 수 있을 것입니다.

**참고 문헌:** Hadoop/Avro/Parquet 공식 문서 및 다양한 기술 블로그  등.
